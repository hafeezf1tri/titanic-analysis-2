new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(randomForest)  # Random Forest Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert categorical variables to numeric
titanic_data$Sex <- ifelse(titanic_data$Sex == "male", 1, 0)  # Male = 1, Female = 0
# Convert Pclass into an ordered factor with correct labels
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3),
labels = c("1st Class", "2nd Class", "3rd Class"))
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Define independent (X) and dependent (y) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable (numerical probability of survival)
# Normalize the features (Random Forest is less sensitive, but we standardize for consistency)
X <- as.data.frame(scale(X))  # Standardize independent variables
# Define required packages
packages <- c("randomForest", "caret", "ggplot2", "dplyr")
# Install missing packages
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(randomForest)  # Random Forest Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert Pclass into an ordered factor with proper labels
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3),
labels = c("1st Class", "2nd Class", "3rd Class"))
# Convert Sex into numeric
titanic_data$Sex <- ifelse(titanic_data$Sex == "male", 1, 0)  # Male = 1, Female = 0
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Store original Age values before scaling (for later use in visualization)
titanic_data$Original_Age <- titanic_data$Age
# Normalize features (except Pclass) for consistency in training
titanic_data$Age <- scale(titanic_data$Age)  # Standardize Age
# Define independent (X) and dependent (y) variables
X <- titanic_data[, c("Pclass", "Sex", "Age")]  # Features
y <- titanic_data$Survived  # Target variable
# Combine features, target variable, and original Age for later use
titanic_data_prepared <- cbind(X, Survived = y, Original_Age = titanic_data$Original_Age)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data_prepared[trainIndex, ]
test_data <- titanic_data_prepared[-trainIndex, ]
# Train a Random Forest model to predict survival probability
set.seed(42)
rf_model <- randomForest(Survived ~ Pclass + Sex + Age, data = train_data, ntree = 500, mtry = 3, importance = TRUE)
# Print model summary
print(rf_model)
# Predict survival probability on test data
rf_preds <- predict(rf_model, newdata = test_data)
# Cap predictions between 0 and 1 (Survival probability must be valid)
rf_preds <- pmax(pmin(rf_preds, 1.0), 0.0)
# Print first few predictions
print(head(rf_preds))
# Create a dataframe for visualization with original Age values
scatter_data <- data.frame(Age = test_data$Original_Age, Pclass = test_data$Pclass, PredictedSurvival = rf_preds)
# Scatter plot: Age vs. Predicted Survival Probability (Colored by Pclass)
ggplot(scatter_data, aes(x = Age, y = PredictedSurvival, color = Pclass)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "loess", color = "black", linetype = "dashed") +
theme_minimal() +
labs(title = "Predicted Survival Probability Based on Age and Pclass (Random Forest)",
x = "Age (Years)",
y = "Predicted Survival Probability",
color = "Passenger Class") +
scale_color_manual(values = c("red", "blue", "green")) +  # Proper class colors
scale_y_continuous(limits = c(0, 1)) +  # Cap Y-axis at 1.0
scale_x_continuous(breaks = seq(floor(min(scatter_data$Age)), ceiling(max(scatter_data$Age)), by = 5))  # Proper Age Labels
# Define required packages
packages <- c("e1071", "caret", "ggplot2", "dplyr")
# Install missing packages
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(e1071)  # Support Vector Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert Pclass into an ordinal factor
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3), labels = c("1st Class", "2nd Class", "3rd Class"))
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Store original Age values before scaling (for later use in plotting)
titanic_data$Original_Age <- titanic_data$Age
# Normalize only Age (SVR is sensitive to scaling, but we don't scale Pclass)
titanic_data$Age <- scale(titanic_data$Age)
# Select features (Pclass, Age) and target (Survived)
X <- titanic_data[, c("Pclass", "Age")]  # Features
y <- titanic_data$Survived  # Target variable
# Combine features and target into a new dataframe
titanic_data_prepared <- cbind(X, Survived = y, Original_Age = titanic_data$Original_Age)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data_prepared[trainIndex, ]
test_data <- titanic_data_prepared[-trainIndex, ]
# Train an SVR model with a linear kernel to ensure correct ordinal handling
set.seed(42)
svr_model <- svm(Survived ~ Pclass + Age, data = train_data, kernel = "linear", cost = 1, epsilon = 0.1)
# Print model summary
print(svr_model)
# Predict survival probability on test data
svr_preds <- predict(svr_model, newdata = test_data)
# Cap predictions between 0 and 1 (Survival probability must be valid)
svr_preds <- pmax(pmin(svr_preds, 1.0), 0.0)
# Print first few predictions
print(head(svr_preds))
# Create a dataframe for visualization
scatter_data <- data.frame(Age = test_data$Original_Age, Pclass = test_data$Pclass, PredictedSurvival = svr_preds)
# Scatter plot: Age vs. Predicted Survival Probability (Colored by Pclass)
ggplot(scatter_data, aes(x = Age, y = PredictedSurvival, color = Pclass)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "loess", color = "black", linetype = "dashed") +
theme_minimal() +
labs(title = "Predicted Survival Probability Based on Age and Pclass (SVR)",
x = "Age (Years)",
y = "Predicted Survival Probability",
color = "Passenger Class") +
scale_color_manual(values = c("red", "blue", "green")) +  # Proper class colors
scale_y_continuous(limits = c(0, 1)) +  # Cap Y-axis at 1.0
scale_x_continuous(breaks = seq(floor(min(scatter_data$Age)), ceiling(max(scatter_data$Age)), by = 5))  # Proper Age Labels
# Define required packages
packages <- c("randomForest", "caret", "ggplot2", "dplyr")
# Install missing packages
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(randomForest)  # Random Forest Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert Pclass into an ordered factor with proper labels
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3),
labels = c("1st Class", "2nd Class", "3rd Class"))
# Convert Sex into numeric
titanic_data$Sex <- ifelse(titanic_data$Sex == "male", 1, 0)  # Male = 1, Female = 0
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Store original Age values before scaling (for later use in visualization)
titanic_data$Original_Age <- titanic_data$Age
# Normalize features (except Pclass) for consistency in training
titanic_data$Age <- scale(titanic_data$Age)  # Standardize Age
# Define independent (X) and dependent (y) variables
X <- titanic_data[, c("Pclass", "Sex", "Age")]  # Features
y <- titanic_data$Survived  # Target variable
# Combine features, target variable, and original Age for later use
titanic_data_prepared <- cbind(X, Survived = y, Original_Age = titanic_data$Original_Age)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data_prepared[trainIndex, ]
test_data <- titanic_data_prepared[-trainIndex, ]
# Train a Random Forest model to predict survival probability
set.seed(42)
rf_model <- randomForest(Survived ~ Pclass + Sex + Age, data = train_data, ntree = 500, mtry = 3, importance = TRUE)
# Print model summary
print(rf_model)
# Predict survival probability on test data
rf_preds <- predict(rf_model, newdata = test_data)
# Cap predictions between 0 and 1 (Survival probability must be valid)
rf_preds <- pmax(pmin(rf_preds, 1.0), 0.0)
# Print first few predictions
print(head(rf_preds))
# Create a dataframe for visualization with original Age values
scatter_data <- data.frame(Age = test_data$Original_Age, Pclass = test_data$Pclass, PredictedSurvival = rf_preds)
# Scatter plot: Age vs. Predicted Survival Probability (Colored by Pclass)
ggplot(scatter_data, aes(x = Age, y = PredictedSurvival, color = Pclass)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "loess", color = "black", linetype = "dashed") +
theme_minimal() +
labs(title = "Predicted Survival Probability Based on Age and Pclass (Random Forest)",
x = "Age (Years)",
y = "Predicted Survival Probability",
color = "Passenger Class") +
scale_color_manual(values = c("red", "blue", "green")) +  # Proper class colors
scale_y_continuous(limits = c(0, 1)) +  # Cap Y-axis at 1.0
scale_x_continuous(breaks = seq(floor(min(scatter_data$Age)), ceiling(max(scatter_data$Age)), by = 5))  # Proper Age Labels
# Load necessary libraries
library(e1071)  # For SVR
library(caret)  # For data partitioning
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Select relevant columns
titanic_data <- titanic_data[, c("Survived", "Pclass", "Age")]
# Handle missing values (remove rows with NA)
titanic_data <- na.omit(titanic_data)
# Split the dataset into training (80%) and testing (20%) sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(titanic_data$Survived, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
test_data <- titanic_data[-trainIndex, ]
# Train SVR model
svr_model <- svm(Survived ~ Pclass + Age, data = train_data, type = "eps-regression", kernel = "radial")
# Make predictions
predictions <- predict(svr_model, test_data)
# Evaluate model performance
mse <- mean((test_data$Survived - predictions)^2)
cat("Mean Squared Error:", mse, "\n")
# Display a sample of predictions
head(data.frame(Actual = test_data$Survived, Predicted = predictions))
# Load necessary libraries
library(e1071)   # For SVR
library(caret)   # For data partitioning
library(ggplot2) # For visualization
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Select relevant columns
titanic_data <- titanic_data[, c("Survived", "Pclass", "Age")]
# Handle missing values (remove rows with NA)
titanic_data <- na.omit(titanic_data)
# Split the dataset into training (80%) and testing (20%) sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(titanic_data$Survived, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
test_data <- titanic_data[-trainIndex, ]
# Train SVR model
svr_model <- svm(Survived ~ Pclass + Age, data = train_data, type = "eps-regression", kernel = "radial")
# Make predictions
predictions <- predict(svr_model, test_data)
# Evaluate model performance
mse <- mean((test_data$Survived - predictions)^2)
cat("Mean Squared Error:", mse, "\n")
# Combine actual and predicted data
results <- data.frame(Actual = test_data$Survived, Predicted = predictions, Age = test_data$Age, Pclass = test_data$Pclass)
# Scatter plot: Actual vs. Predicted survival values
ggplot(results, aes(x = Actual, y = Predicted)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Actual vs Predicted Survival (SVR)",
x = "Actual Survival",
y = "Predicted Survival") +
theme_minimal()
# Regression plot: Age vs Predicted survival
ggplot(results, aes(x = Age, y = Predicted, color = as.factor(Pclass))) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Age vs Predicted Survival (SVR)",
x = "Age",
y = "Predicted Survival",
color = "Pclass") +
theme_minimal()
packages <- c("rpart", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
library(rpart)  # For Decision Tree Regression
library(caret)  # For dataset splitting and evaluation
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# Train Decision Tree Regression model
dt_model <- rpart(Survived ~ ., data = train_data, method = "anova")
# Plot the tree (optional)
plot(dt_model)
text(dt_model, pretty = 0)
# Predict on test set
dt_preds <- predict(dt_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-style comparison
dt_class_preds <- ifelse(dt_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((dt_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - dt_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# Predict on validation set
val_preds <- predict(dt_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
# Define required packages
packages <- c("randomForest", "caret", "ggplot2", "dplyr")
# Install missing packages
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(randomForest)  # Random Forest Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert Pclass into an ordered factor with proper labels
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3),
labels = c("1st Class", "2nd Class", "3rd Class"))
# Convert Sex into numeric
titanic_data$Sex <- ifelse(titanic_data$Sex == "male", 1, 0)  # Male = 1, Female = 0
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Store original Age values before scaling (for later use in visualization)
titanic_data$Original_Age <- titanic_data$Age
# Normalize features (except Pclass) for consistency in training
titanic_data$Age <- scale(titanic_data$Age)  # Standardize Age
# Define independent (X) and dependent (y) variables
X <- titanic_data[, c("Pclass", "Sex", "Age")]  # Features
y <- titanic_data$Survived  # Target variable
# Combine features, target variable, and original Age for later use
titanic_data_prepared <- cbind(X, Survived = y, Original_Age = titanic_data$Original_Age)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data_prepared[trainIndex, ]
test_data <- titanic_data_prepared[-trainIndex, ]
# Train a Random Forest model to predict survival probability
set.seed(42)
rf_model <- randomForest(Survived ~ Pclass + Sex + Age, data = train_data, ntree = 500, mtry = 3, importance = TRUE)
# Print model summary
print(rf_model)
# Predict survival probability on test data
rf_preds <- predict(rf_model, newdata = test_data)
# Cap predictions between 0 and 1 (Survival probability must be valid)
rf_preds <- pmax(pmin(rf_preds, 1.0), 0.0)
# Print first few predictions
print(head(rf_preds))
# Create a dataframe for visualization with original Age values
scatter_data <- data.frame(Age = test_data$Original_Age, Pclass = test_data$Pclass, PredictedSurvival = rf_preds)
# Scatter plot: Age vs. Predicted Survival Probability (Colored by Pclass)
ggplot(scatter_data, aes(x = Age, y = PredictedSurvival, color = Pclass)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "loess", color = "black", linetype = "dashed") +
theme_minimal() +
labs(title = "Predicted Survival Probability Based on Age and Pclass (Random Forest)",
x = "Age (Years)",
y = "Predicted Survival Probability",
color = "Passenger Class") +
scale_color_manual(values = c("red", "blue", "green")) +  # Proper class colors
scale_y_continuous(limits = c(0, 1)) +  # Cap Y-axis at 1.0
scale_x_continuous(breaks = seq(floor(min(scatter_data$Age)), ceiling(max(scatter_data$Age)), by = 5))  # Proper Age Labels
# Load necessary libraries
library(e1071)   # For SVR
library(caret)   # For data partitioning
library(ggplot2) # For visualization
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Select relevant columns
titanic_data <- titanic_data[, c("Survived", "Pclass", "Age")]
# Handle missing values (remove rows with NA)
titanic_data <- na.omit(titanic_data)
# Split the dataset into training (80%) and testing (20%) sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(titanic_data$Survived, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
test_data <- titanic_data[-trainIndex, ]
# Train SVR model
svr_model <- svm(Survived ~ Pclass + Age, data = train_data, type = "eps-regression", kernel = "radial")
# Make predictions
predictions <- predict(svr_model, test_data)
# Evaluate model performance
mse <- mean((test_data$Survived - predictions)^2)
cat("Mean Squared Error:", mse, "\n")
# Combine actual and predicted data
results <- data.frame(Actual = test_data$Survived, Predicted = predictions, Age = test_data$Age, Pclass = test_data$Pclass)
# Scatter plot: Actual vs. Predicted survival values
ggplot(results, aes(x = Actual, y = Predicted)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Actual vs Predicted Survival (SVR)",
x = "Actual Survival",
y = "Predicted Survival") +
theme_minimal()
# Regression plot: Age vs Predicted survival
ggplot(results, aes(x = Age, y = Predicted, color = as.factor(Pclass))) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Age vs Predicted Survival (SVR)",
x = "Age",
y = "Predicted Survival",
color = "Pclass") +
theme_minimal()
# Define required packages
packages <- c("randomForest", "caret", "ggplot2", "dplyr")
# Install missing packages
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the required libraries
library(randomForest)  # Random Forest Regression
library(caret)   # Data splitting and preprocessing
library(ggplot2) # Visualization
library(dplyr)   # Data manipulation
# Load dataset (Ensure Titanic_Cleaned.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert Pclass into an ordered factor with proper labels
titanic_data$Pclass <- factor(titanic_data$Pclass, levels = c(1, 2, 3),
labels = c("1st Class", "2nd Class", "3rd Class"))
# Convert Sex into numeric
titanic_data$Sex <- ifelse(titanic_data$Sex == "male", 1, 0)  # Male = 1, Female = 0
# Remove unnecessary columns (if any)
titanic_data$No. <- NULL
# Remove rows with missing Age values
titanic_data <- titanic_data[!is.na(titanic_data$Age), ]
# Store original Age values before scaling (for later use in visualization)
titanic_data$Original_Age <- titanic_data$Age
# Normalize features (except Pclass) for consistency in training
titanic_data$Age <- scale(titanic_data$Age)  # Standardize Age
# Define independent (X) and dependent (y) variables
X <- titanic_data[, c("Pclass", "Sex", "Age")]  # Features
y <- titanic_data$Survived  # Target variable
# Combine features, target variable, and original Age for later use
titanic_data_prepared <- cbind(X, Survived = y, Original_Age = titanic_data$Original_Age)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data_prepared[trainIndex, ]
test_data <- titanic_data_prepared[-trainIndex, ]
# Train a Random Forest model to predict survival probability
set.seed(42)
rf_model <- randomForest(Survived ~ Pclass + Sex + Age, data = train_data, ntree = 500, mtry = 3, importance = TRUE)
# Print model summary
print(rf_model)
# Predict survival probability on test data
rf_preds <- predict(rf_model, newdata = test_data)
# Cap predictions between 0 and 1 (Survival probability must be valid)
rf_preds <- pmax(pmin(rf_preds, 1.0), 0.0)
# Print first few predictions
print(head(rf_preds))
# Create a dataframe for visualization with original Age values
scatter_data <- data.frame(Age = test_data$Original_Age, Pclass = test_data$Pclass, PredictedSurvival = rf_preds)
# Scatter plot: Age vs. Predicted Survival Probability (Colored by Pclass)
ggplot(scatter_data, aes(x = Age, y = PredictedSurvival, color = Pclass)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "loess", color = "black", linetype = "dashed") +
theme_minimal() +
labs(title = "Predicted Survival Probability Based on Age and Pclass (Random Forest)",
x = "Age (Years)",
y = "Predicted Survival Probability",
color = "Passenger Class") +
scale_color_manual(values = c("red", "blue", "green")) +  # Proper class colors
scale_y_continuous(limits = c(0, 1)) +  # Cap Y-axis at 1.0
scale_x_continuous(breaks = seq(floor(min(scatter_data$Age)), ceiling(max(scatter_data$Age)), by = 5))  # Proper Age Labels
# Load necessary libraries
library(e1071)   # For SVR
library(caret)   # For data partitioning
library(ggplot2) # For visualization
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Select relevant columns
titanic_data <- titanic_data[, c("Survived", "Pclass", "Age")]
# Handle missing values (remove rows with NA)
titanic_data <- na.omit(titanic_data)
# Split the dataset into training (80%) and testing (20%) sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(titanic_data$Survived, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
test_data <- titanic_data[-trainIndex, ]
# Train SVR model
svr_model <- svm(Survived ~ Pclass + Age, data = train_data, type = "eps-regression", kernel = "radial")
# Make predictions
predictions <- predict(svr_model, test_data)
# Evaluate model performance
mse <- mean((test_data$Survived - predictions)^2)
cat("Mean Squared Error:", mse, "\n")
# Combine actual and predicted data
results <- data.frame(Actual = test_data$Survived, Predicted = predictions, Age = test_data$Age, Pclass = test_data$Pclass)
# Scatter plot: Actual vs. Predicted survival values
ggplot(results, aes(x = Actual, y = Predicted)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Actual vs Predicted Survival (SVR)",
x = "Actual Survival",
y = "Predicted Survival") +
theme_minimal()
# Regression plot: Age vs Predicted survival
ggplot(results, aes(x = Age, y = Predicted, color = as.factor(Pclass))) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Age vs Predicted Survival (SVR)",
x = "Age",
y = "Predicted Survival",
color = "Pclass") +
theme_minimal()
