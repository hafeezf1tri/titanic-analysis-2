train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# Train Decision Tree Regression model
dt_model <- rpart(Survived ~ ., data = train_data, method = "anova")
# Plot the tree (optional)
plot(dt_model)
text(dt_model, pretty = 0)
# Predict on test set
dt_preds <- predict(dt_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-style comparison
dt_class_preds <- ifelse(dt_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((dt_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - dt_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# Predict on validation set
val_preds <- predict(dt_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("randomForest", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(randomForest)  # For Random Forest Regression
library(caret)  # For dataset splitting and evaluation
# ðŸ“Œ Step 2: Load and Prepare the Dataset
# Load dataset (Ensure Titanic_processed.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
# Convert categorical variable 'Sex' to factor (if not already encoded)
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
# ðŸ“Œ Step 3: Split Dataset into Train (80%), Test (10%), Validation (10%)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# ðŸ“Œ Step 4: Train a Random Forest Regression Model
set.seed(42)  # Ensure reproducibility
rf_model <- randomForest(Survived ~ ., data = train_data, ntree = 500, importance = TRUE)
# ðŸ“Œ Step 5: Evaluate Model Performance
# Predict on test set
rf_preds <- predict(rf_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-like evaluation
rf_class_preds <- ifelse(rf_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((rf_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - rf_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# ðŸ“Œ Step 6: Validate the Model
# Predict on validation set
val_preds <- predict(rf_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
# ðŸ“Œ Step 7: Feature Importance
# Show which features contribute the most to predictions
importance(rf_model)
varImpPlot(rf_model)  # Plot feature importance
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("randomForest", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(randomForest)  # For Random Forest Regression
library(caret)  # For dataset splitting and evaluation
# ðŸ“Œ Step 2: Load and Prepare the Dataset
# Load dataset (Ensure Titanic_processed.csv is in the working directory)
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
# Convert categorical variable 'Sex' to factor (if not already encoded)
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
# ðŸ“Œ Step 3: Split Dataset into Train (80%), Test (10%), Validation (10%)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# ðŸ“Œ Step 4: Train a Random Forest Regression Model
set.seed(42)  # Ensure reproducibility
rf_model <- randomForest(Survived ~ ., data = train_data, ntree = 500, importance = TRUE)
# ðŸ“Œ Step 5: Evaluate Model Performance
# Predict on test set
rf_preds <- predict(rf_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-like evaluation
rf_class_preds <- ifelse(rf_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((rf_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - rf_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# ðŸ“Œ Step 6: Validate the Model
# Predict on validation set
val_preds <- predict(rf_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
# ðŸ“Œ Step 7: Feature Importance
# Show which features contribute the most to predictions
importance(rf_model)
varImpPlot(rf_model)  # Plot feature importance
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("ggplot2", "dplyr")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(ggplot2)
library(dplyr)
# ðŸ“Œ Step 2: Load the Cleaned Dataset
titanic_cleaned <- read.csv("Titanic_Cleaned.csv")
# ðŸ“Œ Step 3: Define Numeric Columns to Check for Outliers
numeric_columns <- c("Age", "SibSp", "PrCh", "Fare")
# ðŸ“Œ Step 4: Create Boxplots for Each Numeric Feature
# Use ggplot2 to visualize outliers in each numeric column
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
for (col in numeric_columns) {
boxplot(titanic_cleaned[[col]], main=paste("Boxplot of", col), col="gold")
}
# ðŸ“Œ Step 5: Reset Plot Layout
par(mfrow=c(1,1))
# Load necessary library
library(dplyr)
# Load Titanic dataset (replace 'Titanic.csv' with your actual file path)
df <- read.csv("Titanic.csv")
# Round Age to the nearest whole number
df <- df %>%
mutate(Age = round(Age, 0))  # Round 0.5 and above to the next whole number
# Floor Fare to remove decimal points
df <- df %>%
mutate(Fare = floor(Fare))
# Save the processed dataset
write.csv(df, "Titanic_processed.csv", row.names = FALSE)
# Display first few rows of the dataset
head(df)
# ============================================
# Titanic Dataset: Plot Independent Variables vs. Survived (with Value Ranges)
# ============================================
# Install required packages if not already installed
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(reshape2)) install.packages("reshape2")
if (!require(dplyr)) install.packages("dplyr")
# Load libraries
library(ggplot2)
library(reshape2)
library(dplyr)
# ============================================
# 1. Load the Dataset
# ============================================
# Ensure that Titanic_processed.csv is in your working directory
titanic_data <- read.csv("Titanic_processed.csv")
# ============================================
# 2. Data Preprocessing
# ============================================
# Remove 'No.' column if it exists
if ("No." %in% colnames(titanic_data)) {
titanic_data <- titanic_data %>% select(-No.)
}
# Convert categorical variables to factors
titanic_data$Pclass <- as.factor(titanic_data$Pclass)
titanic_data$Sex <- as.factor(titanic_data$Sex)
titanic_data$Survived <- as.factor(titanic_data$Survived)
# ============================================
# 3. Apply Value Ranges (Filtering)
# ============================================
# Limit Age from 1 to 80
titanic_data <- subset(titanic_data, Age >= 1 & Age <= 80)
# Limit Fare from 1 to 600
titanic_data <- subset(titanic_data, Fare >= 1 & Fare <= 600)
# ============================================
# 4. Reshape Data for Plotting
# ============================================
# Reshape dataset into long format using melt()
titanic_melted <- melt(titanic_data, id.vars = "Survived",
measure.vars = c("Pclass", "Sex", "Age", "SibSp", "PrCh", "Fare"))
# ============================================
# 5. Plot Independent Variables vs. Survived
# ============================================
# Facet plot to compare all independent variables in one figure
plot <- ggplot(titanic_melted, aes(x = value, y = as.factor(Survived))) +
geom_jitter(alpha = 0.6, color = "blue", width = 0.3, height = 0.2) + # Scatter plot with jitter
facet_wrap(~ variable, scales = "free_x") +                          # Separate plots for each variable
labs(title = "Independent Variables vs. Survived (Age: 1-80, Fare: 1-600)",
x = "Independent Variables",
y = "Survived") +
theme_minimal()
# Display the plot
print(plot)
# ============================================
# 6. Save Plot as Image
# ============================================
# Save the plot as a PNG image in the working directory
ggsave("Titanic_Combined_ScatterPlot_Range_Age1-80_Fare1-600.png",
plot = plot, width = 12, height = 8, dpi = 300)
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("ggplot2", "dplyr")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(ggplot2)
library(dplyr)
# ðŸ“Œ Step 2: Load the Cleaned Dataset
titanic_cleaned <- read.csv("Titanic_Cleaned.csv")
# ðŸ“Œ Step 3: Define Numeric Columns to Check for Outliers
numeric_columns <- c("Age", "SibSp", "PrCh", "Fare")
# ðŸ“Œ Step 4: Create Boxplots for Each Numeric Feature
# Use ggplot2 to visualize outliers in each numeric column
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
for (col in numeric_columns) {
boxplot(titanic_cleaned[[col]], main=paste("Boxplot of", col), col="gold")
}
# ðŸ“Œ Step 5: Reset Plot Layout
par(mfrow=c(1,1))
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("ggplot2", "dplyr")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(ggplot2)
library(dplyr)
# ðŸ“Œ Step 2: Load the Cleaned Dataset
titanic_cleaned <- read.csv("Titanic_processed.csv")
# ðŸ“Œ Step 3: Define Numeric Columns to Check for Outliers
numeric_columns <- c("Age", "SibSp", "PrCh", "Fare")
# ðŸ“Œ Step 4: Create Boxplots for Each Numeric Feature
# Use ggplot2 to visualize outliers in each numeric column
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
for (col in numeric_columns) {
boxplot(titanic_cleaned[[col]], main=paste("Boxplot of", col), col="gold")
}
# ðŸ“Œ Step 5: Reset Plot Layout
par(mfrow=c(1,1))
packages <- c("ggplot2", "dplyr")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(ggplot2)
library(dplyr)
# ðŸ“Œ Step 2: Load the Cleaned Dataset
titanic_cleaned <- read.csv("Titanic_Cleaned.csv")
# ðŸ“Œ Step 3: Define Numeric Columns to Check for Outliers
numeric_columns <- c("Age", "SibSp", "PrCh", "Fare")
# ðŸ“Œ Step 4: Create Boxplots for Each Numeric Feature
# Use ggplot2 to visualize outliers in each numeric column
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
for (col in numeric_columns) {
boxplot(titanic_cleaned[[col]], main=paste("Boxplot of", col), col="gold")
}
# ðŸ“Œ Step 5: Reset Plot Layout
par(mfrow=c(1,1))
packages <- c("rpart", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
library(rpart)  # For Decision Tree Regression
library(caret)  # For dataset splitting and evaluation
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# Train Decision Tree Regression model
dt_model <- rpart(Survived ~ ., data = train_data, method = "anova")
# Plot the tree (optional)
plot(dt_model)
text(dt_model, pretty = 0)
# Predict on test set
dt_preds <- predict(dt_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-style comparison
dt_class_preds <- ifelse(dt_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((dt_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - dt_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# Predict on validation set
val_preds <- predict(dt_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
# ðŸ“Œ Step 1: Install Required Packages (if not already installed)
packages <- c("rpart", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(rpart)   # For Decision Tree Regression
library(caret)   # For dataset splitting and evaluation
# ðŸ“Œ Step 2: Load and Prepare the Dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Convert categorical variable 'Sex' to a factor
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
# ðŸ“Œ Step 3: Split Dataset into Train (80%), Test (10%), Validation (10%)
set.seed(42)
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# ðŸ“Œ Step 4: Train a Decision Tree with Adjusted Parameters
dt_model <- rpart(
Survived ~ .,
data = train_data,
method = "anova",
control = rpart.control(cp = 0.001, minsplit = 5, maxdepth = 5)
)
# ðŸ“Œ Step 5: Visualize the Decision Tree (Forced Split)
plot(dt_model)
text(dt_model, pretty = 0)
packages <- c("rpart", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
library(rpart)  # For Decision Tree Regression
library(caret)  # For dataset splitting and evaluation
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# Train Decision Tree Regression model
dt_model <- rpart(Survived ~ ., data = train_data, method = "anova")
# Plot the tree (optional)
plot(dt_model)
text(dt_model, pretty = 0)
# Predict on test set
dt_preds <- predict(dt_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-style comparison
dt_class_preds <- ifelse(dt_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((dt_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - dt_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# Predict on validation set
val_preds <- predict(dt_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
packages <- c("randomForest", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load the necessary libraries
library(randomForest)  # For Random Forest Regression
library(caret)  # For dataset splitting and evaluation
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
# Convert categorical variable 'Sex' to factor (if not already encoded)
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
#Step 3: Split Dataset into Train (80%), Test (10%), Validation (10%)
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
#Step 4: Train a Random Forest Regression Model
set.seed(42)  # Ensure reproducibility
rf_model <- randomForest(Survived ~ ., data = train_data, ntree = 500, importance = TRUE)
#Step 5: Evaluate Model Performance
# Predict on test set
rf_preds <- predict(rf_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-like evaluation
rf_class_preds <- ifelse(rf_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((rf_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - rf_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
#Step 6: Validate the Model
# Predict on validation set
val_preds <- predict(rf_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
#Step 7: Feature Importance
# Show which features contribute the most to predictions
importance(rf_model)
varImpPlot(rf_model)  # Plot feature importance
packages <- c("rpart", "caret")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
library(rpart)  # For Decision Tree Regression
library(caret)  # For dataset splitting and evaluation
# Load the dataset
titanic_data <- read.csv("Titanic_Cleaned.csv")
# Remove unnecessary column (Passenger No.)
titanic_data$No. <- NULL
titanic_data$Sex <- as.factor(titanic_data$Sex)
# Define dependent (y) and independent (X) variables
X <- titanic_data[, !(names(titanic_data) %in% c("Survived"))]  # Features
y <- titanic_data$Survived  # Target variable
set.seed(42)  # For reproducibility
# Create train index (80%)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- titanic_data[trainIndex, ]
temp_data <- titanic_data[-trainIndex, ]
# Split remaining 20% into test (10%) and validation (10%)
testIndex <- createDataPartition(temp_data$Survived, p = 0.5, list = FALSE)
test_data <- temp_data[testIndex, ]
validation_data <- temp_data[-testIndex, ]
# Train Decision Tree Regression model
dt_model <- rpart(Survived ~ ., data = train_data, method = "anova")
# Plot the tree (optional)
plot(dt_model)
text(dt_model, pretty = 0)
# Predict on test set
dt_preds <- predict(dt_model, newdata = test_data)
# Convert continuous predictions to binary (0 or 1) for classification-style comparison
dt_class_preds <- ifelse(dt_preds > 0.5, 1, 0)
# Calculate Mean Squared Error (MSE)
mse <- mean((dt_preds - test_data$Survived)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared (coefficient of determination)
ss_total <- sum((test_data$Survived - mean(test_data$Survived))^2)
ss_residual <- sum((test_data$Survived - dt_preds)^2)
r2 <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r2))
# Predict on validation set
val_preds <- predict(dt_model, newdata = validation_data)
# Convert to binary for evaluation
val_class_preds <- ifelse(val_preds > 0.5, 1, 0)
# Calculate validation accuracy
val_acc <- mean(val_class_preds == validation_data$Survived)
print(paste("Validation Accuracy:", val_acc))
